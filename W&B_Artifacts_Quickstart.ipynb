{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W&B Artifacts Quickstart",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n7jdRlSVQmO"
      },
      "source": [
        "# Dataset and model versioning with W&B\n",
        "Use W&B Artifacts for dataset versioning and model management. The Artifacts API is simple: \n",
        "\n",
        "### Save a dataset or model version\n",
        "1. `artifact = wandb.Artifact('my-artifact', type='artifact-type')`: Construct a new artifact to log. You can also set a dictionary of metadata on the artifact.\n",
        "2. `artifact.add_file('my-file.csv')`: Add files to the artifact to save. You can also add whole directories, or log a reference to an external bucket like S3 instead of uploading files to W&B.\n",
        "3. `run.log_artifact(artifact)`: Save the artifact to W&B. This happens asynchronously, so make sure to let the upload finish before trying to use the artifact elsewhere.\n",
        "\n",
        "### Use a saved dataset or model version\n",
        "1. `run.use_artifact('my-artifact:latest')`: Mark that saved artifact as input to the current pipeline step.\n",
        "2. `artifact_dir = artifact.download()`: Pull down the saved artifact data\n",
        "\n",
        "### In this quickstart\n",
        "In this tiny example, we'll simulate a common workflow:\n",
        "1. Save a dataset with `log_artifact`\n",
        "2. Use the dataset to train a model with `use_artifact`\n",
        "3. Save the resulting model with `log_artifact`\n",
        "4. Save an updated dataset version wtih `log_artifact`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV-sqyj6SpjW"
      },
      "source": [
        "# Install the Weights & Biases library\n",
        "!pip install wandb -qqq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX4j1KMESq8-"
      },
      "source": [
        "# 1. Log a dataset version as an artifact\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# Initialize a new W&B run to track this job\n",
        "run = wandb.init(project=\"artifacts-quickstart\", job_type=\"dataset-creation\")\n",
        "\n",
        "# Create a sample dataset to log as an artifact\n",
        "f = open('my-dataset.txt', 'w')\n",
        "f.write('Imagine this is a big dataset.')\n",
        "f.close()\n",
        "\n",
        "# Create a new artifact, which is a sample dataset\n",
        "dataset = wandb.Artifact('my-dataset', type='dataset')\n",
        "# Add files to the artifact, in this case a simple text file\n",
        "dataset.add_file('my-dataset.txt')\n",
        "# Log the artifact to save it as an output of this run\n",
        "run.log_artifact(dataset)\n",
        "\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myfJoE1iUrdG"
      },
      "source": [
        "# 2. Use that dataset to train a model\n",
        "run = wandb.init(project=\"artifacts-quickstart\", job_type=\"model-training\")\n",
        "\n",
        "# Pull down that dataset you logged in the last run\n",
        "artifact = run.use_artifact('my-dataset:latest')\n",
        "artifact_dir = artifact.download()\n",
        "print(open(os.path.join(artifact_dir, 'my-dataset.txt')).read())\n",
        "\n",
        "# Simulate tracking a model file with this simple txt\n",
        "f = open('my-model.txt', 'w')\n",
        "f.write('Imagine this is a model file.')\n",
        "f.close()\n",
        "\n",
        "# Save a model after training\n",
        "model = wandb.Artifact('my-model', type='model')\n",
        "model.add_file('my-model.txt')\n",
        "run.log_artifact(model)\n",
        "\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbq_bxPshCkt"
      },
      "source": [
        "# 3. Log a new dataset version\n",
        "\n",
        "# Initialize a new W&B run to track this job\n",
        "run = wandb.init(project=\"artifacts-quickstart\", job_type=\"dataset-creation\")\n",
        "\n",
        "# Update the dataset\n",
        "f = open('my-dataset.txt', 'w')\n",
        "f.write('Here is an edited dataset!')\n",
        "f.close()\n",
        "\n",
        "# Log to the same named artifact, but with updated data\n",
        "artifact = wandb.Artifact('my-dataset', type='dataset')\n",
        "artifact.add_file('my-dataset.txt')\n",
        "run.log_artifact(artifact)\n",
        "\n",
        "# Now you have a new artifact version logged!\n",
        "\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thank you"
      ],
      "metadata": {
        "id": "On20gm9CFLAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGDn7-12iKes"
      },
      "source": [
        "Now in W&B you have a new version of that dataset logged. It looks something like [this page](https://wandb.ai/carey/artifacts-quickstart/artifacts/dataset/my-dataset/c51a86259b3821da2c2f/files/my-dataset.txt):\n",
        "\n",
        "<img src=\"https://i.imgur.com/4LFApxA.png\" width=\"500\" alt=\"Weights & Biases\" />\n"
      ]
    }
  ]
}